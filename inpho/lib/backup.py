#!/usr/bin/python
from datetime import date
from glob import iglob
import os
import os.path
import shlex
import subprocess
import tarfile

from sqlalchemy.engine.url import make_url

import inpho.config
import inpho.corpus

# configure path information
backup_path = inpho.config.get('general', 'backup_path')
remote_file = os.path.join('/Users/inpho/Sites/sep/entries.tar')

def sep(remote_file=None):
    """ Creates a backup of all SEP entries. """
    timestamp = date.today().strftime("%Y%m%d")
    backup_file = os.path.join(backup_path, 'sep_%s.tar' % timestamp)

    tar = tarfile.open(backup_file, 'w')
    for name in iglob(os.path.join(inpho.corpus.path, '*/*.html')):
        tar.add(name, arcname=name.replace(inpho.corpus.path, ''))

    tar.close()
    
    if remote_file:
        os.symlink(backup_file, remote_file)

def data(filename=None, remote_file=None):
    """
    Backs up the InPhO database, excluding all user information.

    Equivilent to:
    mysqldump $LOGIN --no-data > $OUTFILE
    mysqldump $LOGIN --tables entity groups idea idea_instance_of idea_link_to institution journal journal_abbr nationality ontotree profession school_of_thought searchpatterns sep_areas sepentries thinker thinker_has_influenced thinker_has_nationality thinker_has_profession work >> $OUTFILE
    """
    # initialize file
    if filename is None:
        timestamp = date.today().strftime("%Y%m%d")
        filename = os.path.join(backup_path, 'inpho_%s.sql' % timestamp)

    # Get login arguments
    login = mysql_login_args()
    
    print "dumping schema..."
    # Dump complete database schema
    # Execute `mysqldump $LOGIN --no-data > $OUTFILE`
    args = ['mysqldump', login, '--no-data']
    with open(filename, 'w') as f:
        schema = subprocess.call(_clean_args(args), stdout=f)
   
    print "dumping data..."
    # Dump entity tables, do not dump user data
    # mysqldump $LOGIN --tables entity groups idea idea_instance_of idea_link_to institution journal journal_abbr nationality ontotree profession school_of_thought searchpatterns sep_areas sepentries thinker thinker_has_influenced thinker_has_nationality thinker_has_profession work >> $OUTFILE
    args = ['mysqldump', login, '--tables']
    tables = ["entity groups institution school_of_thought work",
              "idea idea_instance_of idea_link_to ontotree",
              "journal journal_abbr",
              "thinker nationality profession thinker_has_influenced",
              "thinker_has_nationality thinker_has_profession",
              "searchpatterns sep_areas sepentries"]
    args.extend(tables)
    with open(filename, 'a') as f:
        data = subprocess.call(_clean_args(args), stdout=f)

def _clean_args(args):
    """ Helper to clean up arg string """
    # join together
    args = ' '.join(args)
    # transform into subprocess-compatible list
    return shlex.split(args)


def mysql_login_args():
    """ creates the login arguments for mysql, based on inpho.config """
    # TODO: Migrate to inpho.model without necessitating model import
    url = make_url(inpho.config.get('sqlalchemy', 'url'))

    login = "-u %(username)s -p%(password)s -h %(host)s" % url.__dict__
    if url.port:
        login += " --port=%(port)s" % url.__dict__
    login += " %(database)s" % url.__dict__

    return login

def graph(filename=None, remote_file=None):
    """
    Backs up the most recent InPhO graph. This may be better done by just
    symlinking the daily data mining runs generated by inpho/corpus/sep.py, but
    since we may include multiple corpora, this will be necessary to write.
    """
    # initialize file
    if filename is None:
        timestamp = date.today().strftime("%Y%m%d")
        filename = os.path.join(backup_path, 'graph_%s.sql' % timestamp)

    # Get login arguments
    login = mysql_login_args()
    
    args = ['mysqldump', login, '--tables']
    tables = ["idea_graph_edges", "thinker_graph_edges",
              "idea_thinker_graph_edges"]
    args.extend(tables)
    with open(filename, 'a') as f:
        data = subprocess.call(_clean_args(args), stdout=f)

if __name__ == '__main__':
    from optparse import OptionParser
    usage = "usage: $prog [options]"

    parser = OptionParser(usage)
    parser.set_defaults(mode=None, safe=True)
    parser.add_option('--sep', action='store_const', 
                      dest='mode', const='sep',
                      help="backup the SEP corpus")
    parser.add_option('--data', action='store_const', 
                      dest='mode', const='data',
                      help="backup inpho entities")
    parser.add_option('--safe', action='store_true', dest='safe',
                      help="safe data backup, excludes user info [default]")
    parser.add_option('--unsafe', action='store_false', dest='safe',
                      help="unsafe data backup, includes user info")
    parser.add_option('--graph', action='store_const',
                      dest='mode', const='graph',
                      help="backup graph data")
    options, args = parser.parse_args()

    if options.mode == 'sep':
        sep()
    elif options.mode == 'data':
        data()
    elif options.mode == 'graph':
        graph()
